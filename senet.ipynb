{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f332eb2-5f90-48dd-8592-c96bb39c21bb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-06T09:29:19.622667Z",
     "iopub.status.busy": "2022-12-06T09:29:19.622309Z",
     "iopub.status.idle": "2022-12-06T09:29:19.630167Z",
     "shell.execute_reply": "2022-12-06T09:29:19.629597Z",
     "shell.execute_reply.started": "2022-12-06T09:29:19.622623Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def mymodel(act, units):\n",
    "    text_in = Input(shape=(768,),name='text_input')#[768]\n",
    "    img_in = Input(shape=(512,),name='image_input')#[512]\n",
    "    \n",
    "    \n",
    "    avg_pool_text = Dense(1)(text_in)\n",
    "    avg_pool_image = Dense(1)(img_in)\n",
    "    \n",
    "    concate = Concatenate(axis=1)([avg_pool_text, avg_pool_image])\n",
    "    fc_1 = Dense(1, activation='relu')(concate)\n",
    "    fc_2 = Dense(2, activation='sigmoid')(fc_1)\n",
    "    fc_2 = Reshape((2, 1))(fc_2)\n",
    "    \n",
    "    \n",
    "    concate_feature = Concatenate(axis=1)([text_in, img_in])#1280\n",
    "    # concate_feature = Dropout(0.1)(concate_feature)\n",
    "    concate_feature = Reshape((2, 640))(concate_feature)\n",
    "    \n",
    "\n",
    "    dot_result = Dot(axes=1)([fc_2, concate_feature])\n",
    "    \n",
    "    dot_result = Reshape((640,))(dot_result)\n",
    "    \n",
    "    # dot_result = Dense(512)(dot_result)\n",
    "    # dot_result = Dense(256)(dot_result)\n",
    "    # dot_result = Dense(128)(dot_result)\n",
    "    dot_result = Dense(64)(dot_result)\n",
    "    dot_result = Dense(32)(dot_result)\n",
    "    \n",
    "    \n",
    "    output = Dense(units,activation=act)(dot_result)\n",
    "    model = Model([text_in, img_in], output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0594a234-85bf-49e8-8b50-c1cc5ccf2b3d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-06T09:29:20.204533Z",
     "iopub.status.busy": "2022-12-06T09:29:20.204214Z",
     "iopub.status.idle": "2022-12-06T09:29:21.538887Z",
     "shell.execute_reply": "2022-12-06T09:29:21.538402Z",
     "shell.execute_reply.started": "2022-12-06T09:29:20.204516Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def categorical_crossentropy_with_prior(y_true, y_pred, tau=1.0):\n",
    "    \"\"\"带先验分布的交叉熵\n",
    "    注：y_pred不用加softmax\n",
    "    \"\"\"\n",
    "    prior = [0.25,0.42,0.33]  # 自己定义好prior，shape为[num_classes]\n",
    "    log_prior = K.constant(np.log([i + 1e-8 for i in prior]))\n",
    "    for _ in range(K.ndim(y_pred) - 1):\n",
    "        log_prior = K.expand_dims(log_prior, 0)\n",
    "    y_pred = y_pred + tau * log_prior\n",
    "    return K.categorical_crossentropy(y_true, y_pred, from_logits=True)\n",
    "\n",
    "def sparse_categorical_crossentropy_with_prior(y_true, y_pred, tau=1.0):\n",
    "    \"\"\"带先验分布的稀疏交叉熵\n",
    "    注：y_pred不用加softmax\n",
    "    \"\"\"\n",
    "    prior = [0.21, 0.28, 0.43, 0.08]    # 自己定义好prior，shape为[num_classes][0.25,0.42,0.33]  [0.14,0.86] [0.21,0.79] [0.61,0.39][0.88,0.12]\n",
    "    #[0.14, 0.48, 0.29, 0.08] [0.21, 0.28, 0.43, 0.08][0.61, 0.28, 0.09, 0.03]#!!!!!替换点\n",
    "    log_prior = K.constant(np.log([i + 1e-8 for i in prior]))\n",
    "    for _ in range(K.ndim(y_pred) - 1):\n",
    "        log_prior = K.expand_dims(log_prior, 0)\n",
    "    y_pred = y_pred + tau * log_prior\n",
    "    return K.sparse_categorical_crossentropy(y_true, y_pred, from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd198993-7bc2-4b44-ad90-fc6bff2d8a93",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-06T09:29:24.553496Z",
     "iopub.status.busy": "2022-12-06T09:29:24.553029Z",
     "iopub.status.idle": "2022-12-06T09:29:24.653972Z",
     "shell.execute_reply": "2022-12-06T09:29:24.653522Z",
     "shell.execute_reply.started": "2022-12-06T09:29:24.553477Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-06 09:29:24.594298: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2022-12-06 09:29:24.594333: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-12-06 09:29:24.594349: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (xyxyxxxy-tfotywoiijsp-main): /proc/driver/nvidia/version does not exist\n",
      "2022-12-06 09:29:24.594499: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/usr/local/lib/python3.8/site-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, Conv1D, Dropout, GlobalAveragePooling1D, Concatenate, Conv2D, GlobalAveragePooling2D, Dense, Embedding, LSTM, Dot, Reshape\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications.densenet import DenseNet121\n",
    "import tensorflow.keras.preprocessing.sequence as S\n",
    "from tensorflow.keras.optimizers import Adam,SGD\n",
    "\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "model = mymodel('softmax', 4)#sigmoid#!!!!!!!替换点\n",
    "model.compile(loss=sparse_categorical_crossentropy_with_prior, optimizer=Adam(lr=1e-4), metrics=['sparse_categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "093ef37e-c5f3-47e6-85db-38751e661fe6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-06T09:29:34.698929Z",
     "iopub.status.busy": "2022-12-06T09:29:34.698529Z",
     "iopub.status.idle": "2022-12-06T09:29:34.721030Z",
     "shell.execute_reply": "2022-12-06T09:29:34.720623Z",
     "shell.execute_reply.started": "2022-12-06T09:29:34.698909Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " text_input (InputLayer)        [(None, 768)]        0           []                               \n",
      "                                                                                                  \n",
      " image_input (InputLayer)       [(None, 512)]        0           []                               \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 1)            769         ['text_input[0][0]']             \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 1)            513         ['image_input[0][0]']            \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 2)            0           ['dense[0][0]',                  \n",
      "                                                                  'dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 1)            3           ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 2)            4           ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 1280)         0           ['text_input[0][0]',             \n",
      "                                                                  'image_input[0][0]']            \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 2, 1)         0           ['dense_3[0][0]']                \n",
      "                                                                                                  \n",
      " reshape_1 (Reshape)            (None, 2, 640)       0           ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " dot (Dot)                      (None, 1, 640)       0           ['reshape[0][0]',                \n",
      "                                                                  'reshape_1[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_2 (Reshape)            (None, 640)          0           ['dot[0][0]']                    \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 64)           41024       ['reshape_2[0][0]']              \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 32)           2080        ['dense_4[0][0]']                \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 4)            132         ['dense_5[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 44,525\n",
      "Trainable params: 44,525\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2bf859d1-8aea-4b47-99cf-f3fc5c93d07d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-06T08:49:49.887079Z",
     "iopub.status.busy": "2022-12-06T08:49:49.886772Z",
     "iopub.status.idle": "2022-12-06T08:49:51.019437Z",
     "shell.execute_reply": "2022-12-06T08:49:51.018947Z",
     "shell.execute_reply.started": "2022-12-06T08:49:49.887060Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_image_path = 'memotion3features/train_image_feature.csv'\n",
    "val_image_path = 'memotion3features/val_image_feature.csv'\n",
    "test_image_path = 'memotion3features/test_image_feature.csv'\n",
    "\n",
    "train_text_path = 'memotion3features/train_text_feature.csv'\n",
    "val_text_path = 'memotion3features/val_text_feature.csv'\n",
    "test_text_path = 'memotion3features/test_text_feature.csv'\n",
    "\n",
    "train_label_path = 'train.csv'\n",
    "val_label_path = 'val.csv'\n",
    "\n",
    "\n",
    "def load_data(text_path, image_path, label_path):\n",
    "    text_features = pd.read_csv(text_path)\n",
    "    image_features = pd.read_csv(image_path)\n",
    "    labels_all = pd.read_csv(label_path)['c2_labels2']#!!!!!!替换点\n",
    "    \n",
    "    # features = pd.concat([text_features,image_features],axis=1)\n",
    "#     print(features.shape)\n",
    "    \n",
    "    return [text_features, image_features], labels_all\n",
    "\n",
    "train_X, train_y = load_data(train_text_path, train_image_path, train_label_path)\n",
    "val_X, val_y = load_data(val_text_path, val_image_path, val_label_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "562115d3-bc12-4681-be65-49b201e57fe5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-06T08:01:08.587564Z",
     "iopub.status.busy": "2022-12-06T08:01:08.586983Z",
     "iopub.status.idle": "2022-12-06T08:01:29.117824Z",
     "shell.execute_reply": "2022-12-06T08:01:29.117297Z",
     "shell.execute_reply.started": "2022-12-06T08:01:08.587542Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/30\n",
      "17/28 [=================>............] - ETA: 0s - loss: 1.2311 - sparse_categorical_accuracy: 0.3718train f1: 0.3847970789498792 val f1: 0.3890091860878044\n",
      "\n",
      "Epoch 1: val_sparse_categorical_accuracy improved from -inf to 0.33533, saving model to best.h5\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 1.2270 - sparse_categorical_accuracy: 0.3750 - val_loss: 1.2002 - val_sparse_categorical_accuracy: 0.3353\n",
      "Epoch 2/30\n",
      "16/28 [================>.............] - ETA: 0s - loss: 1.2267 - sparse_categorical_accuracy: 0.3989train f1: 0.38709229526638 val f1: 0.4006778544313788\n",
      "\n",
      "Epoch 2: val_sparse_categorical_accuracy improved from 0.33533 to 0.34933, saving model to best.h5\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 1.2261 - sparse_categorical_accuracy: 0.3937 - val_loss: 1.1976 - val_sparse_categorical_accuracy: 0.3493\n",
      "Epoch 3/30\n",
      "15/28 [===============>..............] - ETA: 0s - loss: 1.2176 - sparse_categorical_accuracy: 0.3953train f1: 0.3890687980381045 val f1: 0.3745340148718713\n",
      "\n",
      "Epoch 3: val_sparse_categorical_accuracy did not improve from 0.34933\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 1.2252 - sparse_categorical_accuracy: 0.3906 - val_loss: 1.2032 - val_sparse_categorical_accuracy: 0.3220\n",
      "Epoch 4/30\n",
      "18/28 [==================>...........] - ETA: 0s - loss: 1.2234 - sparse_categorical_accuracy: 0.4039train f1: 0.3921332618602106 val f1: 0.38768341092085834\n",
      "\n",
      "Epoch 4: val_sparse_categorical_accuracy did not improve from 0.34933\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 1.2243 - sparse_categorical_accuracy: 0.3966 - val_loss: 1.2011 - val_sparse_categorical_accuracy: 0.3353\n",
      "Epoch 5/30\n",
      "16/28 [================>.............] - ETA: 0s - loss: 1.2302 - sparse_categorical_accuracy: 0.3794train f1: 0.4003559861946832 val f1: 0.3936887701867645\n",
      "\n",
      "Epoch 5: val_sparse_categorical_accuracy did not improve from 0.34933\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 1.2233 - sparse_categorical_accuracy: 0.3914 - val_loss: 1.1992 - val_sparse_categorical_accuracy: 0.3427\n",
      "Epoch 6/30\n",
      "16/28 [================>.............] - ETA: 0s - loss: 1.2229 - sparse_categorical_accuracy: 0.4048train f1: 0.39991096306324514 val f1: 0.38795598504093126\n",
      "\n",
      "Epoch 6: val_sparse_categorical_accuracy did not improve from 0.34933\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 1.2229 - sparse_categorical_accuracy: 0.4090 - val_loss: 1.2011 - val_sparse_categorical_accuracy: 0.3367\n",
      "Epoch 7/30\n",
      "16/28 [================>.............] - ETA: 0s - loss: 1.2236 - sparse_categorical_accuracy: 0.3955train f1: 0.39940967759836277 val f1: 0.3779922844737282\n",
      "\n",
      "Epoch 7: val_sparse_categorical_accuracy did not improve from 0.34933\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 1.2220 - sparse_categorical_accuracy: 0.3883 - val_loss: 1.2045 - val_sparse_categorical_accuracy: 0.3253\n",
      "Epoch 8/30\n",
      "17/28 [=================>............] - ETA: 0s - loss: 1.2243 - sparse_categorical_accuracy: 0.3959train f1: 0.3961426730050025 val f1: 0.4094128475917352\n",
      "\n",
      "Epoch 8: val_sparse_categorical_accuracy improved from 0.34933 to 0.36067, saving model to best.h5\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 1.2213 - sparse_categorical_accuracy: 0.4059 - val_loss: 1.1900 - val_sparse_categorical_accuracy: 0.3607\n",
      "Epoch 9/30\n",
      "17/28 [=================>............] - ETA: 0s - loss: 1.2205 - sparse_categorical_accuracy: 0.4010train f1: 0.4002168799477729 val f1: 0.3455078129622802\n",
      "\n",
      "Epoch 9: val_sparse_categorical_accuracy did not improve from 0.36067\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 1.2202 - sparse_categorical_accuracy: 0.4043 - val_loss: 1.2169 - val_sparse_categorical_accuracy: 0.2900\n",
      "Epoch 10/30\n",
      "15/28 [===============>..............] - ETA: 0s - loss: 1.2235 - sparse_categorical_accuracy: 0.4026train f1: 0.39660950570889614 val f1: 0.3812280198817597\n",
      "\n",
      "Epoch 10: val_sparse_categorical_accuracy did not improve from 0.36067\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 1.2191 - sparse_categorical_accuracy: 0.3959 - val_loss: 1.2012 - val_sparse_categorical_accuracy: 0.3287\n",
      "Epoch 11/30\n",
      "17/28 [=================>............] - ETA: 0s - loss: 1.2087 - sparse_categorical_accuracy: 0.4051train f1: 0.4100563939845962 val f1: 0.3913437168921955\n",
      "\n",
      "Epoch 11: val_sparse_categorical_accuracy did not improve from 0.36067\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 1.2183 - sparse_categorical_accuracy: 0.4081 - val_loss: 1.1955 - val_sparse_categorical_accuracy: 0.3420\n",
      "Epoch 12/30\n",
      "17/28 [=================>............] - ETA: 0s - loss: 1.2171 - sparse_categorical_accuracy: 0.4030train f1: 0.4156809247451126 val f1: 0.37864779224822737\n",
      "\n",
      "Epoch 12: val_sparse_categorical_accuracy did not improve from 0.36067\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 1.2175 - sparse_categorical_accuracy: 0.4061 - val_loss: 1.2087 - val_sparse_categorical_accuracy: 0.3253\n",
      "Epoch 13/30\n",
      "18/28 [==================>...........] - ETA: 0s - loss: 1.2091 - sparse_categorical_accuracy: 0.4134train f1: 0.41478921825352966 val f1: 0.38681385654871875\n",
      "\n",
      "Epoch 13: val_sparse_categorical_accuracy did not improve from 0.36067\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 1.2167 - sparse_categorical_accuracy: 0.4077 - val_loss: 1.2040 - val_sparse_categorical_accuracy: 0.3340\n",
      "Epoch 14/30\n",
      "15/28 [===============>..............] - ETA: 0s - loss: 1.2134 - sparse_categorical_accuracy: 0.4034train f1: 0.41550367650668923 val f1: 0.3864641670966175\n",
      "\n",
      "Epoch 14: val_sparse_categorical_accuracy did not improve from 0.36067\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 1.2157 - sparse_categorical_accuracy: 0.4023 - val_loss: 1.2058 - val_sparse_categorical_accuracy: 0.3327\n",
      "Epoch 15/30\n",
      "16/28 [================>.............] - ETA: 0s - loss: 1.2093 - sparse_categorical_accuracy: 0.4209train f1: 0.4095852688303983 val f1: 0.40291052012134476\n",
      "\n",
      "Epoch 15: val_sparse_categorical_accuracy did not improve from 0.36067\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 1.2149 - sparse_categorical_accuracy: 0.4169 - val_loss: 1.1941 - val_sparse_categorical_accuracy: 0.3520\n",
      "Epoch 16/30\n",
      "16/28 [================>.............] - ETA: 0s - loss: 1.2116 - sparse_categorical_accuracy: 0.3970train f1: 0.41669369141132667 val f1: 0.38502695808531634\n",
      "\n",
      "Epoch 16: val_sparse_categorical_accuracy did not improve from 0.36067\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 1.2139 - sparse_categorical_accuracy: 0.4089 - val_loss: 1.2065 - val_sparse_categorical_accuracy: 0.3320\n",
      "Epoch 17/30\n",
      "16/28 [================>.............] - ETA: 0s - loss: 1.2125 - sparse_categorical_accuracy: 0.4077train f1: 0.4196163897626113 val f1: 0.3976859110160858\n",
      "\n",
      "Epoch 17: val_sparse_categorical_accuracy did not improve from 0.36067\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 1.2130 - sparse_categorical_accuracy: 0.4096 - val_loss: 1.1980 - val_sparse_categorical_accuracy: 0.3460\n",
      "Epoch 18/30\n",
      "16/28 [================>.............] - ETA: 0s - loss: 1.2133 - sparse_categorical_accuracy: 0.4167train f1: 0.41418522878132336 val f1: 0.38961927058891926\n",
      "\n",
      "Epoch 18: val_sparse_categorical_accuracy did not improve from 0.36067\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 1.2123 - sparse_categorical_accuracy: 0.4097 - val_loss: 1.2043 - val_sparse_categorical_accuracy: 0.3347\n",
      "Epoch 19/30\n",
      "17/28 [=================>............] - ETA: 0s - loss: 1.2147 - sparse_categorical_accuracy: 0.4177train f1: 0.4257885816382238 val f1: 0.3805497854511666\n",
      "\n",
      "Epoch 19: val_sparse_categorical_accuracy did not improve from 0.36067\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 1.2113 - sparse_categorical_accuracy: 0.4190 - val_loss: 1.2106 - val_sparse_categorical_accuracy: 0.3293\n",
      "Epoch 20/30\n",
      "17/28 [=================>............] - ETA: 0s - loss: 1.2096 - sparse_categorical_accuracy: 0.4203train f1: 0.4183762855015253 val f1: 0.37769926260873027\n",
      "\n",
      "Epoch 20: val_sparse_categorical_accuracy did not improve from 0.36067\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 1.2106 - sparse_categorical_accuracy: 0.4194 - val_loss: 1.2098 - val_sparse_categorical_accuracy: 0.3227\n",
      "Epoch 21/30\n",
      "17/28 [=================>............] - ETA: 0s - loss: 1.2062 - sparse_categorical_accuracy: 0.4251train f1: 0.41257522634984806 val f1: 0.38301052543829966\n",
      "\n",
      "Epoch 21: val_sparse_categorical_accuracy did not improve from 0.36067\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 1.2096 - sparse_categorical_accuracy: 0.4131 - val_loss: 1.2043 - val_sparse_categorical_accuracy: 0.3267\n",
      "Epoch 22/30\n",
      "17/28 [=================>............] - ETA: 0s - loss: 1.2078 - sparse_categorical_accuracy: 0.4219train f1: 0.42332799854626285 val f1: 0.38026266021560134\n",
      "\n",
      "Epoch 22: val_sparse_categorical_accuracy did not improve from 0.36067\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 1.2086 - sparse_categorical_accuracy: 0.4186 - val_loss: 1.2083 - val_sparse_categorical_accuracy: 0.3273\n",
      "Epoch 23/30\n",
      "17/28 [=================>............] - ETA: 0s - loss: 1.2076 - sparse_categorical_accuracy: 0.4212train f1: 0.4231714719671629 val f1: 0.3702883001700769\n",
      "\n",
      "Epoch 23: val_sparse_categorical_accuracy did not improve from 0.36067\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 1.2081 - sparse_categorical_accuracy: 0.4167 - val_loss: 1.2134 - val_sparse_categorical_accuracy: 0.3153\n",
      "Epoch 24/30\n",
      "17/28 [=================>............] - ETA: 0s - loss: 1.2020 - sparse_categorical_accuracy: 0.4173train f1: 0.42972942818715754 val f1: 0.3731442704929681\n",
      "\n",
      "Epoch 24: val_sparse_categorical_accuracy did not improve from 0.36067\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 1.2073 - sparse_categorical_accuracy: 0.4220 - val_loss: 1.2149 - val_sparse_categorical_accuracy: 0.3207\n",
      "Epoch 25/30\n",
      "16/28 [================>.............] - ETA: 0s - loss: 1.2034 - sparse_categorical_accuracy: 0.4116train f1: 0.42219976960488165 val f1: 0.38297955470932016\n",
      "\n",
      "Epoch 25: val_sparse_categorical_accuracy did not improve from 0.36067\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 1.2061 - sparse_categorical_accuracy: 0.4173 - val_loss: 1.2051 - val_sparse_categorical_accuracy: 0.3280\n",
      "Epoch 26/30\n",
      "15/28 [===============>..............] - ETA: 0s - loss: 1.2113 - sparse_categorical_accuracy: 0.4078train f1: 0.4341592798545021 val f1: 0.3831692539097302\n",
      "\n",
      "Epoch 26: val_sparse_categorical_accuracy did not improve from 0.36067\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 1.2054 - sparse_categorical_accuracy: 0.4166 - val_loss: 1.2127 - val_sparse_categorical_accuracy: 0.3327\n",
      "Epoch 27/30\n",
      "16/28 [================>.............] - ETA: 0s - loss: 1.2112 - sparse_categorical_accuracy: 0.4307train f1: 0.4268027650421195 val f1: 0.37114414630918746\n",
      "\n",
      "Epoch 27: val_sparse_categorical_accuracy did not improve from 0.36067\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 1.2045 - sparse_categorical_accuracy: 0.4220 - val_loss: 1.2131 - val_sparse_categorical_accuracy: 0.3160\n",
      "Epoch 28/30\n",
      "15/28 [===============>..............] - ETA: 0s - loss: 1.1992 - sparse_categorical_accuracy: 0.4214train f1: 0.428155087348175 val f1: 0.39291272276569444\n",
      "\n",
      "Epoch 28: val_sparse_categorical_accuracy did not improve from 0.36067\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 1.2037 - sparse_categorical_accuracy: 0.4287 - val_loss: 1.1986 - val_sparse_categorical_accuracy: 0.3427\n",
      "Epoch 29/30\n",
      "17/28 [=================>............] - ETA: 0s - loss: 1.2015 - sparse_categorical_accuracy: 0.4249train f1: 0.43554338546735727 val f1: 0.37446290987140823\n",
      "\n",
      "Epoch 29: val_sparse_categorical_accuracy did not improve from 0.36067\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 1.2028 - sparse_categorical_accuracy: 0.4253 - val_loss: 1.2157 - val_sparse_categorical_accuracy: 0.3220\n",
      "Epoch 30/30\n",
      "16/28 [================>.............] - ETA: 0s - loss: 1.2042 - sparse_categorical_accuracy: 0.4312train f1: 0.4291914200304117 val f1: 0.37058364513250913\n",
      "\n",
      "Epoch 30: val_sparse_categorical_accuracy did not improve from 0.36067\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 1.2018 - sparse_categorical_accuracy: 0.4309 - val_loss: 1.2130 - val_sparse_categorical_accuracy: 0.3140\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9eb9bc7c40>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import LambdaCallback\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "filepath='best.h5'\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_sparse_categorical_accuracy', verbose=1, save_best_only=True,mode='max',period=1)\n",
    "\n",
    "batch_print_callback = LambdaCallback(on_epoch_end=lambda batch,\\\n",
    "                    logs: print(\"train f1:\", f1_score(train_y, \\\n",
    "                    model.predict(train_X).argmax(axis=-1), average='weighted'), \\\n",
    "                    \"val f1:\", f1_score(val_y, model.predict(val_X).argmax(axis=-1),\\\n",
    "                    average='weighted')))\n",
    "\n",
    "model.fit(train_X,train_y,batch_size=256,epochs=30,\n",
    "        validation_data=(val_X,val_y),\n",
    "        callbacks=[batch_print_callback,checkpoint] \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b4ace3d6-d41c-4370-a147-25b318086ae3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-06T08:49:54.338486Z",
     "iopub.status.busy": "2022-12-06T08:49:54.338180Z",
     "iopub.status.idle": "2022-12-06T08:49:54.423389Z",
     "shell.execute_reply": "2022-12-06T08:49:54.422979Z",
     "shell.execute_reply.started": "2022-12-06T08:49:54.338468Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model_load = load_model('bestmodel/taskC2_0.4700.h5',custom_objects={'sparse_categorical_crossentropy_with_prior': sparse_categorical_crossentropy_with_prior})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "45f084d1-d10f-4a45-8bf5-c411dcdc769d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-06T08:35:02.781261Z",
     "iopub.status.busy": "2022-12-06T08:35:02.780490Z",
     "iopub.status.idle": "2022-12-06T08:35:03.210851Z",
     "shell.execute_reply": "2022-12-06T08:35:03.210300Z",
     "shell.execute_reply.started": "2022-12-06T08:35:02.781242Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "46a69ce4-f95e-4c0d-9078-e870c3a486dd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-06T08:30:51.587258Z",
     "iopub.status.busy": "2022-12-06T08:30:51.586779Z",
     "iopub.status.idle": "2022-12-06T08:30:51.852944Z",
     "shell.execute_reply": "2022-12-06T08:30:51.852406Z",
     "shell.execute_reply.started": "2022-12-06T08:30:51.587237Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e60f867b-c9c9-40ec-bc27-8023e8442494",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-06T08:31:22.191864Z",
     "iopub.status.busy": "2022-12-06T08:31:22.191487Z",
     "iopub.status.idle": "2022-12-06T08:31:22.194329Z",
     "shell.execute_reply": "2022-12-06T08:31:22.193898Z",
     "shell.execute_reply.started": "2022-12-06T08:31:22.191846Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# confusion_matrix(val_y, predict.argmax(axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "943d1dee-7e68-4bbc-93b0-fb3ec5e87fa4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-06T08:49:56.470446Z",
     "iopub.status.busy": "2022-12-06T08:49:56.470151Z",
     "iopub.status.idle": "2022-12-06T08:49:56.595462Z",
     "shell.execute_reply": "2022-12-06T08:49:56.595051Z",
     "shell.execute_reply.started": "2022-12-06T08:49:56.470428Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4706675292845772"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict = model_load.predict(val_X)\n",
    "f1_score(val_y, predict.argmax(axis=-1), average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5477f1-7ed0-4c1a-84d2-672d36b2d649",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d393338-8ba4-4a20-99bd-a6f26be2638e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
